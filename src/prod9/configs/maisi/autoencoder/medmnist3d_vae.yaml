# =============================================================================
# prod9 MAISI Stage 1 Configuration (MedMNIST 3D)
# VAE with KL divergence regularization
# =============================================================================

output_dir: "outputs/medmnist3d_maisi_stage1"
vae_export_path: "outputs/medmnist3d_maisi_vae.pt"

# =============================================================================
# Model Architecture
# =============================================================================
model:
  autoencoder:
    spatial_dims: 3
    latent_channels: 16
    in_channels: 1
    out_channels: 1
    num_channels: [64, 128, 256, 256]
    attention_levels: [False, False, False, True]
    num_res_blocks: [2, 2, 2, 2]
    norm_num_groups: 32
    num_splits: 2
    save_mem: false

# =============================================================================
# Training Configuration
# =============================================================================
training:
  optimizer:
    lr_g: 1e-4
    lr_d: 2e-4
    b1: 0.5
    b2: 0.9
    weight_decay: 1e-5

  loop:
    sample_every_n_steps: 100

  stability:
    grad_norm_logging: true
    warmup_enabled: true
    warmup_steps: null
    warmup_ratio: 0.02
    warmup_eta_min: 0.0

# =============================================================================
# Data Configuration (MedMNIST 3D)
# =============================================================================
data:
  dataset_name: "all"  # Options: organmnist3d, nodulemnist3d, adrenalmnist3d, fracturemnist3d, vesselmnist3d, synapsemnist3d
  size: 64
  root: "./.medmnist"
  download: true
  intensity_a_min: 0.0
  intensity_a_max: 1.0
  intensity_b_min: -1.0
  intensity_b_max: 1.0
  intensity_clip: true
  batch_size: 4
  num_workers: 4
  cache_num_workers: 0
  train_val_split: 0.9

  augmentation:
    enabled: true
    flip_prob: 0.5
    flip_axes: [0, 1, 2]
    rotate_prob: 0.5
    rotate_range: 0.26
    zoom_prob: 0.5
    zoom_min: 0.9
    zoom_max: 1.1
    shift_intensity_prob: 0.5
    shift_intensity_offset: 0.1

# =============================================================================
# Loss Configuration
# =============================================================================
loss:
  recon_weight: 1.0
  kl_weight: 1.0e-6
  perceptual_weight: 0.5
  adv_weight: 0.1
  lpips_network: "alex"
  is_fake_3d: true
  fake_3d_ratio: 0.5
  discriminator_iter_start: 1500

# =============================================================================
# Discriminator Configuration
# =============================================================================
discriminator:
  num_d: 1
  num_layers_d: 3
  channels: 64

# =============================================================================
# Callbacks Configuration
# =============================================================================
callbacks:
  checkpoint:
    monitor: "val/lpips"
    mode: "min"
    save_top_k: 3
    save_last: true

  early_stop:
    enabled: true
    monitor: "val/lpips"
    patience: 10
    mode: "min"

  lr_monitor: true

  # PyTorch Profiler (disabled by default)
  profiler:
    enabled: false
    profile_cpu: true
    profile_cuda: true
    record_shapes: true
    with_stack: true
    profile_memory: true
    trace_dir: "profiler"

# =============================================================================
# Trainer Configuration
# =============================================================================
trainer:
  max_epochs: 100

  hardware:
    accelerator: "auto"
    devices: "auto"
    precision: "16-mixed"  # bf16 not supported on MPS

  logging:
    log_every_n_steps: 10
    val_check_interval: 1.0
    limit_val_batches: 3

  # Gradient handling
  gradient_clip_val: null
  gradient_clip_algorithm: "norm"
  accumulate_grad_batches: 1

# =============================================================================
# Sliding Window Inference
# =============================================================================
sliding_window:
  enabled: false
  roi_size: [64, 64, 64]
  overlap: 0.5
  sw_batch_size: 1
  mode: "gaussian"
