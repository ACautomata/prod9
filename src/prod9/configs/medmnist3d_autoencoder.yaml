# =============================================================================
# prod9 MedMNIST 3D Stage 1 Configuration
# Complete configuration for VQGAN-style autoencoder training with FSQ
# =============================================================================

# Output paths
output_dir: ".output/medmnist3d_stage1"
autoencoder_export_path: ".output/medmnist3d_autoencoder.pt"

# =============================================================================
# Model Architecture
# =============================================================================
model:
  # AutoencoderFSQ configuration
  autoencoder:
    spatial_dims: 3
    in_channels: 1
    out_channels: 1
    levels: [8, 8, 8]  # 8^3 = 512 codebook size
    num_channels: [64, 128, 256, 512]  # Reduced channel sizes for memory efficiency (4 layers for 64^3 input)
    attention_levels: [False, False, False, True]  # Attention only in deepest layer
    num_res_blocks: [2, 2, 2, 2]  # Residual blocks per layer (4 layers)
    norm_num_groups: 8  # Group normalization groups
    num_splits: 2  # No splitting for small 64^3 inputs (default is 16)

  # MultiScalePatchDiscriminator configuration
  discriminator:
    spatial_dims: 3
    in_channels: 1
    out_channels: 1
    num_d: 1           
    channels: 64       
    num_layers_d: 3    
    kernel_size: 4              
    activation: ["LEAKYRELU", {"negative_slope": 0.2}]
    norm: "BATCH"
    minimum_size_im: 64

  # MedMNIST 3D doesn't need modality embeddings (single modality)
  num_modalities: 1
  contrast_embed_dim: null  # Stage 1 doesn't need contrast embeddings

# =============================================================================
# Training Configuration
# =============================================================================
training:
  # Optimizer settings
  optimizer:
    lr_g: 1e-5  # Generator (autoencoder) learning rate
    lr_d: 4e-4  # Discriminator learning rate
    b1: 0.5  # Adam beta1
    b2: 0.999  # Adam beta2
    weight_decay: 1e-3

  # Learning rate scheduler (optional, currently constant)
  scheduler:
    type: "constant"  # Options: constant, cosine, step
    # T_max: 100  # For cosine
    # step_size: 30  # For step
    # gamma: 0.1  # For step
    # eta_min: 0  # For cosine

  # Training loop settings
  loop:
    sample_every_n_steps: 100  # How often to generate samples during training

# =============================================================================
# Data Configuration
# =============================================================================
data:
  # MedMNIST 3D dataset configuration
  dataset_name: "organmnist3d"  # Options: organmnist3d, nodulemnist3d, adrenalmnist3d, fracturemnist3d, vesselmnist3d, synapsemnist3d
  size: 64  # Image size: 28 or 64
  root: "./.medmnist"
  download: true

  # Data loader settings
  batch_size: 2
  num_workers: 4
  train_val_split: 0.9

  # Data augmentation (recommended for MedMNIST 3D due to small sample size)
  augmentation:
    enabled: true
    flip_prob: 0.5
    flip_axes: [0, 1, 2]  # Axial, coronal, sagittal
    rotate_prob: 0.5
    rotate_range: 0.26  # 15 degrees (in radians)
    zoom_prob: 0.5
    zoom_min: 0.9
    zoom_max: 1.1
    shift_intensity_prob: 0.5
    shift_intensity_offset: 0.1  # +/- 10% shift

# =============================================================================
# Loss Configuration
# =============================================================================
loss:
  discriminator_iter_start: 3000  # Discriminator warmup

  # Reconstruction loss (L1)
  reconstruction:
    weight: 1.0

  # Perceptual loss
  perceptual:
    weight: 0.5
    network_type: "medicalnet_resnet10_23datasets"
    is_fake_3d: false

  # Adversarial loss
  adversarial:
    weight: 0.1  # Base weight (scaled adaptively)
    criterion: "hinge"  # hinge, least_squares, bce

  # Commitment loss (FSQ)
  commitment:
    weight: 0.25  # Beta in VQ terminology

  # Adaptive weight calculation
  adaptive:
    max_weight: 100.0  # Clamp adaptive weight
    grad_norm_eps: 0.0001  # Epsilon for gradient norm ratio

# =============================================================================
# Callbacks Configuration
# =============================================================================
callbacks:
  # Model checkpointing
  checkpoint:
    monitor: "val/lpips"
    mode: "min"
    save_top_k: 3
    save_last: true
    every_n_epochs: null  # null = check every epoch

  # Early stopping
  early_stop:
    enabled: true
    monitor: "val/lpips"
    patience: 10
    mode: "min"
    min_delta: 0.0  # Minimum change to qualify as improvement

  # Learning rate monitoring
  lr_monitor: true

# =============================================================================
# Trainer Configuration
# =============================================================================
trainer:
  # Training settings
  max_epochs: 100

  # Hardware
  hardware:
    accelerator: "auto"  # auto, gpu, cpu, mps (Apple Silicon)
    devices: "auto"  # auto, 1, 2, 4, etc.
    precision: "bf16-mixed"  # 32, 16, bf16

  # Logging
  logging:
    log_every_n_steps: 10
    val_check_interval: 1.0  # Validate every N epochs
    limit_train_batches: null  # null = all batches
    limit_val_batches: 5
    logger_version: null  # null = auto-increment

  # Gradient handling (disabled for manual optimization)
  gradient_clip_val: null
  accumulate_grad_batches: 1

  # Debugging/profiling
  profiler: null  # null, simple, advanced, pytorch
  detect_anomaly: false
  benchmark: false

# =============================================================================
# Sliding Window Inference
# =============================================================================
sliding_window:
  # Disable SW for Stage 1 (training uses direct calls)
  enabled: false

  # Window configuration
  roi_size: [64, 64, 64]
  overlap: 0.5  # 0-1, higher = smoother but slower
  sw_batch_size: 1  # Increase if GPU memory allows
  mode: "gaussian"  # gaussian, constant, mean

# =============================================================================
# Metrics Configuration
# =============================================================================
metrics:
  combination:
    # Metric weights for model selection
    weights:
      psnr: 1.0  # PSNR weight (after normalization to [0,1])
      ssim: 1.0  # SSIM weight
      lpips: 1.0  # LPIPS weight

    # PSNR range for normalization (dB)
    psnr_range: [20, 40]  # Typical range for medical image reconstruction
