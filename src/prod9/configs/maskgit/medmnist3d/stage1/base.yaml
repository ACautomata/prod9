# =============================================================================
# prod9 MedMNIST 3D Stage 1 Configuration
# Complete configuration for VQGAN-style autoencoder training with FSQ
# =============================================================================

# Output paths
output_dir: "outputs/medmnist3d_stage1"
autoencoder_export_path: "outputs/medmnist3d_autoencoder.pt"

# =============================================================================
# Model Architecture
# =============================================================================
model:
  # AutoencoderFSQ configuration
  autoencoder:
    spatial_dims: 3
    in_channels: 1
    out_channels: 1
    levels: [8, 8, 8, 6, 5]  # 8^3 = 512 codebook size
    num_channels: [64, 128, 256, 256]  # Reduced channel sizes for memory efficiency (4 layers for 64^3 input)
    attention_levels: [False, False, False, True]  # Attention only in deepest layer
    num_res_blocks: [2, 2, 2, 2]  # Residual blocks per layer (4 layers)
    norm_num_groups: 32  # Group normalization groups
    num_splits: 2  # No splitting for small 64^3 inputs (default is 16)

  # MultiScalePatchDiscriminator configuration
  discriminator:
    spatial_dims: 3
    in_channels: 1
    out_channels: 1
    num_d: 1           
    channels: 64       
    num_layers_d: 3    
    kernel_size: 4              
    activation: ["LEAKYRELU", {"negative_slope": 0.2}]
    norm: "BATCH"
    minimum_size_im: 64

  # MedMNIST 3D doesn't need modality embeddings (single modality)
  num_modalities: 1
  contrast_embed_dim: null  # Stage 1 doesn't need contrast embeddings

# =============================================================================
# Training Configuration
# =============================================================================
training:
  # Optimizer settings
  optimizer:
    lr_g: 1e-4  # Generator (autoencoder) learning rate (reduced for stability)
    lr_d: 2e-4  # Discriminator learning rate (reduced for stability)
    b1: 0.5  # Adam beta1
    b2: 0.95  # Adam beta2
    weight_decay: 1e-5

  # Learning rate scheduler (optional, currently constant)
  scheduler:
    type: "cosine"  # Options: constant, cosine, step
    T_max: 100  # For cosine
    # step_size: 30  # For step
    # gamma: 0.1  # For step
    eta_min: 0  # For cosine

  # Training loop settings
  loop:
    sample_every_n_steps: 100  # How often to generate samples during training

  # Training stability settings
  stability:
    grad_norm_logging: true  # Log gradient norms for monitoring training health
    warmup_enabled: true  # Enable learning rate warmup
    warmup_steps: null  # Auto-calculate based on warmup_ratio (set explicitly to override)
    warmup_ratio: 0.02  # 2% of total training steps for warmup
    warmup_eta_min: 0.0

# =============================================================================
# Data Configuration
# =============================================================================
data:
  # MedMNIST 3D dataset configuration
  # Option 1: Single dataset (backward compatible)
  dataset_name: "all"  # Options: organmnist3d, nodulemnist3d, adrenalmnist3d, fracturemnist3d, vesselmnist3d, synapsemnist3d, "all"
  # Option 2: Multiple datasets (combines all specified datasets)
  dataset_names: null  # null = use dataset_name, or specify list: ["organmnist3d", "nodulemnist3d", ...]

  # Use "all" to combine all 6 MedMNIST 3D datasets (~6200 training samples)
  # Uncomment the line below to enable:
  # dataset_name: "all"

  size: 64  # Image size: 28 or 64
  root: "./.medmnist"
  download: true
  intensity_a_min: 0.0
  intensity_a_max: 1.0
  intensity_b_min: -1.0
  intensity_b_max: 1.0
  intensity_clip: true

  # Data loader settings
  batch_size: 4
  num_workers: 4
  train_val_split: 0.9

  # Data augmentation (recommended for MedMNIST 3D due to small sample size)
  augmentation:
    enabled: true
    flip_prob: 0.5
    flip_axes: [0, 1, 2]  # Axial, coronal, sagittal
    rotate_prob: 0.5
    rotate_range: 0.26  # 15 degrees (in radians)
    zoom_prob: 0.5
    zoom_min: 0.9
    zoom_max: 1.1
    shift_intensity_prob: 0.5
    shift_intensity_offset: 0.1  # +/- 10% shift

# =============================================================================
# Loss Configuration
# =============================================================================
loss:
  discriminator_iter_start: 3000

  # Reconstruction loss (L1)
  reconstruction:
    weight: 1.0

  # Perceptual Loss (LPIPS-based using pretrained network)
  perceptual:
    weight: 0.5
    network_type: "alex"
    is_fake_3d: true
    fake_3d_ratio: 0.5

  # Adversarial loss
  adversarial:
    weight: 0.1
    criterion: "hinge"  # hinge, least_squares, bce

  # Commitment loss (FSQ)
  commitment:
    weight: 0.0

  # Adaptive weight calculation
  adaptive:
    max_weight: 100.0  # Clamp adaptive weight
    grad_norm_eps: 0.0001  # Epsilon for gradient norm ratio

# =============================================================================
# Callbacks Configuration
# =============================================================================
callbacks:
  # Model checkpointing
  checkpoint:
    monitor: "val/lpips"
    mode: "min"
    save_top_k: 3
    save_last: true
    every_n_epochs: null  # null = check every epoch

  # Early stopping
  early_stop:
    enabled: true
    monitor: "val/lpips"
    patience: 10
    mode: "min"
    min_delta: 0.0  # Minimum change to qualify as improvement

  # Learning rate monitoring
  lr_monitor: true

  # PyTorch Profiler (disabled by default)
  profiler:
    enabled: False
    profile_cpu: true
    profile_cuda: true
    record_shapes: true
    with_stack: true
    profile_memory: true
    trace_dir: "profiler"

# =============================================================================
# Trainer Configuration
# =============================================================================
trainer:
  # Training settings
  max_epochs: 100

  # Hardware
  hardware:
    accelerator: "auto"  # auto, gpu, cpu, mps (Apple Silicon)
    devices: "auto"  # auto, 1, 2, 4, etc.
    precision: "16-mixed"  # 32, 16, bf16

  # Logging
  logging:
    log_every_n_steps: 10
    val_check_interval: 1.0  # Validate every N epochs
    limit_train_batches: null  # null = all batches
    limit_val_batches: 5
    logger_version: null  # null = auto-increment

  # Gradient handling
  # For transformer (automatic optimization), set gradient_clip_val here
  gradient_clip_val: null  # Not used for manual optimization
  gradient_clip_algorithm: "norm"
  accumulate_grad_batches: 1

  # Debugging/profiling
  profiler: null  # null, simple, advanced, pytorch
  detect_anomaly: false
  benchmark: false

# =============================================================================
# Sliding Window Inference
# =============================================================================
sliding_window:
  # Disable SW for Stage 1 (training uses direct calls)
  enabled: false

  # Window configuration
  roi_size: [64, 64, 64]
  overlap: 0.5  # 0-1, higher = smoother but slower
  sw_batch_size: 1  # Increase if GPU memory allows
  mode: "gaussian"  # gaussian, constant, mean
