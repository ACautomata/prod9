# =============================================================================
# prod9 MAISI Stage 2 Diffusion Template Configuration
# MAISI: Rectified Flow diffusion training
# CLI: prod9-train-maisi-diffusion train --config <this_file>
# =============================================================================

# =============================================================================
# Output Paths (REQUIRED)
# =============================================================================
output_dir: "outputs/maisi_stage2"  # Directory for checkpoints and logs
vae_path: "outputs/maisi_vae_final.pt"  # Path to trained Stage 1 VAE (REQUIRED)

# =============================================================================
# Model Architecture
# =============================================================================
model:
  # ----------------------------------------------------------------------
  # Diffusion model configuration (Rectified Flow U-Net)
  # All fields optional - can use default settings
  # ----------------------------------------------------------------------
  diffusion:
    spatial_dims: 3  # Spatial dimensions (1-3), default: 3
    in_channels: 4  # Input channels (must match Stage 1 latent_channels), default: 4
    num_channels: [32, 64, 64, 64]  # Channel sizes per layer (as tuple), default: [32, 64, 64, 64]
    attention_levels: [False, False, True, True]  # Attention layers (as tuple), default: [False, False, True, True]
    num_res_blocks: [1, 1, 1, 1]  # Residual blocks per layer (as tuple), default: [1, 1, 1, 1]
    num_head_channels: [0, 0, 32, 32]  # Attention head channels (as tuple), default: [0, 0, 32, 32]
    norm_num_groups: 32  # Group normalization groups, default: 32

# =============================================================================
# Scheduler Configuration (Rectified Flow)
# =============================================================================
scheduler:
  # ----------------------------------------------------------------------
  # Rectified Flow scheduler parameters
  # ----------------------------------------------------------------------
  num_train_timesteps: 1000  # Number of training timesteps, default: 1000
  num_inference_steps: 10  # Number of inference steps (10-30 recommended), default: 10
    # Rectified Flow enables fast generation (10-30 steps vs 1000 for DDPM)

# =============================================================================
# Training Configuration
# =============================================================================
training:
  # ----------------------------------------------------------------------
  # Optimizer settings
  # ----------------------------------------------------------------------
  optimizer:
    lr_g: 1e-4  # Learning rate, default: 1e-4
    # Note: MAISI diffusion uses lr_g (same as single lr in config_schema)

  # ----------------------------------------------------------------------
  # Learning rate scheduler
  # ----------------------------------------------------------------------
  scheduler:
    type: "constant"  # Options: constant, cosine, step
      # constant: no scheduling
      # cosine: cosine annealing (requires T_max, eta_min)
      # step: step decay (requires step_size, gamma)

    # Cosine scheduler parameters (if type: "cosine")
    # T_max: 100  # Maximum number of iterations
    # eta_min: 0  # Minimum learning rate

    # Step scheduler parameters (if type: "step")
    # step_size: 30  # Decay every N epochs
    # gamma: 0.1  # Multiplicative decay factor

    # Warmup configuration (applies to all schedulers)
    warmup:
      enabled: true  # Enable learning rate warmup, default: true
      warmup_steps: null  # Explicit warmup steps (overrides warmup_ratio)
      warmup_ratio: 0.02  # Ratio of total_steps for warmup (2%), default: 0.02
      eta_min: 0.0  # Minimum learning rate after cosine decay, default: 0.0

  # ----------------------------------------------------------------------
  # Training loop settings
  # ----------------------------------------------------------------------
  loop:
    sample_every_n_steps: 100  # How often to generate samples during training, default: 100

  # ----------------------------------------------------------------------
  # Training stability settings
  # ----------------------------------------------------------------------
  stability:
    grad_norm_logging: true  # Log gradient norms for monitoring, default: true
    warmup_enabled: true  # Enable learning rate warmup, default: true
    warmup_steps: null  # Explicit warmup steps (overrides warmup_ratio)
    warmup_ratio: 0.02  # Ratio of total_steps for warmup (2%), default: 0.02
    warmup_eta_min: 0.1  # Minimum learning rate ratio after decay (0.0-1.0), default: 0.1

# =============================================================================
# Data Configuration (BraTS Dataset)
# =============================================================================
data:
  # ----------------------------------------------------------------------
  # Data paths
  # ----------------------------------------------------------------------
  data_dir: "${BRATS_DATA_DIR:data/BraTS}"  # Path to dataset (env var or default)

  # ----------------------------------------------------------------------
  # Modalities to use (BraTS-specific)
  # ----------------------------------------------------------------------
  modalities: ["T1", "T1ce", "T2", "FLAIR"]  # BraTS modalities, default: 4 modalities

  # ----------------------------------------------------------------------
  # Data loader settings
  # ----------------------------------------------------------------------
  batch_size: 2  # Training batch size, default: 2
  num_workers: 4  # Number of data loading workers, default: 4
  cache_num_workers: 0  # CacheDataset worker count, default: 0
  cache_rate: 0.5  # Cache 0-100% of data (1.0 = all in RAM), default: 1.0
  pin_memory: true  # Pin memory for faster GPU transfer, default: true
  train_val_split: 0.8  # Training/validation split ratio, default: 0.8

  # ----------------------------------------------------------------------
  # Training crop size
  # ----------------------------------------------------------------------
  roi_size: [64, 64, 64]  # Training crop size [D, H, W], default: [64, 64, 64]

  # ----------------------------------------------------------------------
  # Preprocessing transforms (same as Stage 1)
  # ----------------------------------------------------------------------
  preprocessing:
    spacing: [1.0, 1.0, 1.0]  # Pixel dimensions [D, H, W], default: [1.0, 1.0, 1.0]
    spacing_mode: "bilinear"  # Resampling mode, default: "bilinear"
    orientation: "RAS"  # NIfTI orientation, default: "RAS"
    intensity_a_min: 0.0  # ScaleIntensityRanged lower bound, default: 0.0
    intensity_a_max: 500.0  # ScaleIntensityRanged upper bound, default: 500.0
    intensity_b_min: -1.0  # Output lower bound after normalization, default: -1.0
    intensity_b_max: 1.0  # Output upper bound after normalization, default: 1.0
    clip: true  # Clip intensities to [a_min, a_max], default: true

  # ----------------------------------------------------------------------
  # Data augmentation
  # ----------------------------------------------------------------------
  augmentation:
    flip_prob: 0.5  # Random flip probability (0-1), default: 0.5
    flip_axes: [0, 1, 2]  # Flip axes [D, H, W], default: null (all axes)

    rotate_prob: 0.5  # Random rotation probability (0-1), default: 0.5
    rotate_max_k: 3  # Max 90-degree rotations (0-3), default: 3
    rotate_axes: [0, 1]  # Rotate in plane [D, H], default: [0, 1]

    shift_intensity_prob: 0.5  # Random intensity shift probability, default: 0.5
    shift_intensity_offset: 0.1  # Intensity shift offset (+/- 10%), default: 0.1

# =============================================================================
# Callbacks Configuration
# =============================================================================
callbacks:
  # ----------------------------------------------------------------------
  # Model checkpointing
  # ----------------------------------------------------------------------
  checkpoint:
    monitor: "val/lpips"  # Metric to monitor for best model, default: val/combined_metric
    mode: "min"  # Mode for monitoring (min=maximize, min=minimize), default: max
    save_top_k: 3  # Number of best models to save, default: 3
    save_last: true  # Always save last checkpoint, default: true
    every_n_epochs: null  # Checkpoint every N epochs (null = disabled)

  # ----------------------------------------------------------------------
  # Early stopping
  # ----------------------------------------------------------------------
  early_stop:
    enabled: true  # Enable early stopping, default: true
    monitor: "val/lpips"  # Metric to monitor, default: val/combined_metric
    patience: 10  # Epochs to wait before stopping, default: 10
    mode: "min"  # Mode for monitoring, default: max
    min_delta: 0.0  # Minimum change to qualify as improvement, default: 0.0
    check_finite: true  # Stop when metric is NaN/Inf, default: true

  # ----------------------------------------------------------------------
  # Learning rate monitoring
  # ----------------------------------------------------------------------
  lr_monitor: true  # Log learning rate, default: true

  # ----------------------------------------------------------------------
  # PyTorch Profiler
  # ----------------------------------------------------------------------
  profiler:
    enabled: false  # Enable PyTorch profiler, default: false
    profile_cpu: true  # Profile CPU activities
    profile_cuda: true  # Profile CUDA activities
    record_shapes: true  # Record tensor shapes
    with_stack: true  # Record stack traces
    profile_memory: true  # Profile memory usage
    trace_dir: "profiler"  # Subdirectory within output_dir for trace files

# =============================================================================
# Trainer Configuration
# =============================================================================
trainer:
  # ----------------------------------------------------------------------
  # Training settings
  # ----------------------------------------------------------------------
  max_epochs: 100  # Maximum number of training epochs, default: 100

  # ----------------------------------------------------------------------
  # Hardware configuration
  # ----------------------------------------------------------------------
  hardware:
    accelerator: "auto"  # Options: auto, cpu, gpu, mps, cuda, tpu, default: auto
    devices: "auto"  # Options: auto, 1, 2, 4, [0, 1], etc., default: auto
    precision: "16-mixed"  # Options: 32, 16-mixed, bf16-mixed (bf16 not on MPS), default: 32

  # ----------------------------------------------------------------------
  # Logging configuration
  # ----------------------------------------------------------------------
  logging:
    log_every_n_steps: 10  # Log every N steps, default: 10
    val_check_interval: 1.0  # Validate every N epochs, default: 1.0
    limit_train_batches: null  # Limit training batches (null = all), default: null
    limit_val_batches: 5.0  # Limit validation batches, default: 5.0
    logger_version: null  # Logger version (null = auto-increment), default: null

  # ----------------------------------------------------------------------
  # Gradient handling
  # ----------------------------------------------------------------------
  gradient_clip_val: 1.0  # Gradient clipping value (null = disabled), default: 1.0
  gradient_clip_algorithm: "norm"  # Options: norm, value, default: norm
  accumulate_grad_batches: 1  # Accumulate gradients over N batches, default: 1

  # ----------------------------------------------------------------------
  # Debugging/profiling
  # ----------------------------------------------------------------------
  profiler: null  # PyTorch profiler (null, simple, advanced, pytorch), default: null
  detect_anomaly: false  # Enable autograd anomaly detection for NaN/Inf, default: false
  benchmark: false  # Enable cudnn benchmarking, default: false

# =============================================================================
# Sliding Window Inference (REQUIRED for diffusion)
# =============================================================================
sliding_window:
  enabled: true  # REQUIRED: Always true for diffusion generation, default: true
    # Must use sliding window to decode large volumes

  roi_size: [64, 64, 64]  # Sliding window size [D, H, W], default: [64, 64, 64]
  overlap: 0.5  # Window overlap 0-1 (higher = smoother but slower), default: 0.5
  sw_batch_size: 1  # Sliding window batch size (increase if GPU memory allows), default: 1
  mode: "gaussian"  # Blending mode: gaussian, constant, mean, default: gaussian

# =============================================================================
# Notes
# =============================================================================
# 1. Rectified Flow Advantages:
#    - Fast generation: 10-30 steps vs 1000 for DDPM
#    - Straight trajectories: Linear interpolation in latent space
#    - No classifier-free guidance needed for most cases
#
# 2. VAE Path:
#    - Must match vae_export_path from Stage 1 config
#    - model.diffusion.in_channels must equal Stage 1 latent_channels
#
# 3. Inference Steps:
#    - num_inference_steps: 10 (fast, good quality)
#    - num_inference_steps: 20-30 (higher quality, slower)
#    - Typical: 10-30 steps (vs 1000 for DDPM)
#
# 4. Environment Variables:
#    - ${BRATS_DATA_DIR:data/BraTS} - Dataset path with default fallback
#
# 5. For MedMNIST3D datasets, replace data section with dataset-specific config:
#    - Add: dataset_name: "organmnist3d" (or other MedMNIST3D datasets)
#    - Add: size: 64 (or 28)
#    - Add: root: "./.medmnist"
#    - Add: download: true
#    - Remove modalities (not used)
